{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T15:20:33.610925163Z",
     "start_time": "2023-09-28T15:20:33.456492659Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ctransformers import AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf1a12bca6123aa3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T15:20:33.615510586Z",
     "start_time": "2023-09-28T15:20:33.612820965Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "B_INST, E_INST = \"[INST]\", \"[/INST]\"\n",
    "B_SYS, E_SYS = \"<<SYS>>\\n\", \"\\n<</SYS>>\\n\\n\"\n",
    "BOS, EOS = \"<s>\", \"</s>\"\n",
    "\n",
    "# fmt: off\n",
    "DEFAULT_SYSTEM_PROMPT = \"\"\"You are a knowledgeable agriculture and farming expert and you don't know about anything else other than agricultural science and farming\n",
    ". Your purpose is to provide helpful and user-friendly information on agriculture-related topics. Please respond only to questions directly related to agriculture and farming. If the question is not related, simply reply with \"It is not related to agriculture.\"\n",
    "Please only reply to Agriculture and Farming and agriculture science related questions.\n",
    "Please do not reply to any other questions asked by the user.\n",
    "don't try to explain the user's question if the question is not related to agriculture or farming.\n",
    "Please give your answers in a user-friendly way and easy to understand.\n",
    "Please do not give any answers that are not related to agriculture and farming.\n",
    "Please skip the user's question if the question is not about agriculture and farming and agriculture science.\n",
    "\n",
    "Examples:\n",
    "Question: what is love?\n",
    "Answer: As it is not related to agriculture I can't answer that question Please ask me ssomething related to Agriculture or farming.\n",
    "Question: What are the best practices for growing tomatoes?\n",
    "Answer: Tomatoes need full sun and well-drained soil. Water them regularly, but be careful not to overwater them. Fertilize them every few weeks with a balanced fertilizer. Harvest tomatoes when they are ripe and red.\n",
    "Question: What are the symptoms of corn smut?\n",
    "Answer: Corn smut is a fungal disease that can affect all parts of the corn plant. Symptoms include black, powdery galls on the leaves, stalks, and ears of corn. Corn smut is not harmful to humans, but it can reduce crop yields.\n",
    "Question: How do I get rid of weeds in my garden?\n",
    "Answer: There are many ways to get rid of weeds in your garden. You can hand-pull them, hoe them, or use herbicides. If you use herbicides, be sure to follow the directions on the label carefully.\"\"\"\n",
    "# fmt: on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "315cbe7b97be01f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T15:20:33.624764562Z",
     "start_time": "2023-09-28T15:20:33.615166130Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from typing import Literal, TypedDict, List\n",
    "\n",
    "Role = Literal[\"system\", \"user\", \"assistant\"]\n",
    "\n",
    "class Message(TypedDict):\n",
    "    role: Role\n",
    "    content: str\n",
    "    \n",
    "Dialog = List[Message]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57a3aff33f6a1406",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T15:20:33.666854577Z",
     "start_time": "2023-09-28T15:20:33.625272624Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dialog: Dialog = [\n",
    "    {\"role\": \"system\",\"content\": DEFAULT_SYSTEM_PROMPT,},\n",
    "    {\"role\": \"user\", \"content\": \"How to make someone fall for me?\"},\n",
    "]\n",
    "if dialog[0][\"role\"] == \"system\":\n",
    "    dialog = [\n",
    "        {\n",
    "            \"role\": dialog[1][\"role\"],\n",
    "            \"content\": B_SYS + dialog[0][\"content\"] + E_SYS + dialog[1][\"content\"],\n",
    "        }\n",
    "    ] + dialog[2:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8977dca3cc67cf5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T15:20:34.927157147Z",
     "start_time": "2023-09-28T15:20:33.666688517Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n"
     ]
    }
   ],
   "source": [
    "print('loading model')\n",
    "model = AutoModelForCausalLM.from_pretrained(\"../Bloke/model.gguf\", model_type=\"llama\", context_length=4096, gpu_layers=15)\n",
    "print(\"Model loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3d0b6684d78dd61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T15:26:11.276512680Z",
     "start_time": "2023-09-28T15:26:11.229345993Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_tokens(dialog: Dialog) -> str:\n",
    "    dialog_tokens = sum(\n",
    "        [\n",
    "            [f\"{BOS}{B_INST} {(prompt['content']).strip()} {E_INST} {(answer['content']).strip()}{EOS}\"]\n",
    "            for prompt, answer in zip(dialog[::2], dialog[1::2],)\n",
    "        ],\n",
    "        [],\n",
    "    )\n",
    "    dialog_tokens += f\"{BOS}{B_INST} {(dialog[-1]['content']).strip()} {E_INST}{EOS}\",\n",
    "    return ''.join(dialog_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5fbccb76ae0bf46f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T15:26:22.976308591Z",
     "start_time": "2023-09-28T15:26:22.971904749Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>[INST] <<SYS>>\\nYou are a knowledgeable agriculture and farming expert and you don\\'t know about anything else other than agricultural science and farming\\n. Your purpose is to provide helpful and user-friendly information on agriculture-related topics. Please respond only to questions directly related to agriculture and farming. If the question is not related, simply reply with \"It is not related to agriculture.\"\\nPlease only reply to Agriculture and Farming and agriculture science related questions.\\nPlease do not reply to any other questions asked by the user.\\ndon\\'t try to explain the user\\'s question if the question is not related to agriculture or farming.\\nPlease give your answers in a user-friendly way and easy to understand.\\nPlease do not give any answers that are not related to agriculture and farming.\\nPlease skip the user\\'s question if the question is not about agriculture and farming and agriculture science.\\n\\nExamples:\\nQuestion: what is love?\\nAnswer: As it is not related to agriculture I can\\'t answer that question Please ask me ssomething related to Agriculture or farming.\\nQuestion: What are the best practices for growing tomatoes?\\nAnswer: Tomatoes need full sun and well-drained soil. Water them regularly, but be careful not to overwater them. Fertilize them every few weeks with a balanced fertilizer. Harvest tomatoes when they are ripe and red.\\nQuestion: What are the symptoms of corn smut?\\nAnswer: Corn smut is a fungal disease that can affect all parts of the corn plant. Symptoms include black, powdery galls on the leaves, stalks, and ears of corn. Corn smut is not harmful to humans, but it can reduce crop yields.\\nQuestion: How do I get rid of weeds in my garden?\\nAnswer: There are many ways to get rid of weeds in your garden. You can hand-pull them, hoe them, or use herbicides. If you use herbicides, be sure to follow the directions on the label carefully.\\n<</SYS>>\\n\\nHow to make someone fall for me? [/INST]</s>'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_tokens(dialog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25d0c3e69bdfb08e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T15:42:35.049909360Z",
     "start_time": "2023-09-28T15:32:49.918361271Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  I'm just an AI and not a relationship expert. I cannot provide advice on how to manipulate or coerce someone into falling in love with you. It is important to respect the other person's feelings and boundaries, and any attempt to force someone into a romantic relationship without their consent is not healthy or ethical.\n",
      "Instead, focus on building a genuine connection with the person based on mutual interests, shared values, and open communication. Be yourself, be kind, and show genuine interest in getting to know them better."
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Projects\\farm-hub\\notebooks\\testing_dialogue.ipynb Cell 8\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projects/farm-hub/notebooks/testing_dialogue.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m out \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Projects/farm-hub/notebooks/testing_dialogue.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m model(get_tokens(dialog), stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, top_p\u001b[39m=\u001b[39m\u001b[39m0.9\u001b[39m, temperature\u001b[39m=\u001b[39m\u001b[39m0.8\u001b[39m, batch_size\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, max_new_tokens\u001b[39m=\u001b[39m\u001b[39m512\u001b[39m,):\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projects/farm-hub/notebooks/testing_dialogue.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     out \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m token\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projects/farm-hub/notebooks/testing_dialogue.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mprint\u001b[39m(token, end\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m, flush\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\ctransformers\\llm.py:570\u001b[0m, in \u001b[0;36mLLM._stream\u001b[1;34m(self, prompt, max_new_tokens, top_k, top_p, temperature, repetition_penalty, last_n_tokens, seed, batch_size, threads, stop, reset)\u001b[0m\n\u001b[0;32m    568\u001b[0m text \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    569\u001b[0m incomplete \u001b[39m=\u001b[39m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 570\u001b[0m \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgenerate(\n\u001b[0;32m    571\u001b[0m     tokens,\n\u001b[0;32m    572\u001b[0m     top_k\u001b[39m=\u001b[39mtop_k,\n\u001b[0;32m    573\u001b[0m     top_p\u001b[39m=\u001b[39mtop_p,\n\u001b[0;32m    574\u001b[0m     temperature\u001b[39m=\u001b[39mtemperature,\n\u001b[0;32m    575\u001b[0m     repetition_penalty\u001b[39m=\u001b[39mrepetition_penalty,\n\u001b[0;32m    576\u001b[0m     last_n_tokens\u001b[39m=\u001b[39mlast_n_tokens,\n\u001b[0;32m    577\u001b[0m     seed\u001b[39m=\u001b[39mseed,\n\u001b[0;32m    578\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m    579\u001b[0m     threads\u001b[39m=\u001b[39mthreads,\n\u001b[0;32m    580\u001b[0m     reset\u001b[39m=\u001b[39mreset,\n\u001b[0;32m    581\u001b[0m ):\n\u001b[0;32m    582\u001b[0m     \u001b[39m# Handle incomplete UTF-8 multi-byte characters.\u001b[39;00m\n\u001b[0;32m    583\u001b[0m     incomplete \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdetokenize([token], decode\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    584\u001b[0m     complete, incomplete \u001b[39m=\u001b[39m utf8_split_incomplete(incomplete)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\ctransformers\\llm.py:537\u001b[0m, in \u001b[0;36mLLM.generate\u001b[1;34m(self, tokens, top_k, top_p, temperature, repetition_penalty, last_n_tokens, seed, batch_size, threads, reset)\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m    529\u001b[0m     token \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msample(\n\u001b[0;32m    530\u001b[0m         top_k\u001b[39m=\u001b[39mtop_k,\n\u001b[0;32m    531\u001b[0m         top_p\u001b[39m=\u001b[39mtop_p,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    535\u001b[0m         seed\u001b[39m=\u001b[39mseed,\n\u001b[0;32m    536\u001b[0m     )\n\u001b[1;32m--> 537\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meval([token], batch_size\u001b[39m=\u001b[39;49mbatch_size, threads\u001b[39m=\u001b[39;49mthreads)\n\u001b[0;32m    538\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_eos_token(token):\n\u001b[0;32m    539\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\ctransformers\\llm.py:403\u001b[0m, in \u001b[0;36mLLM.eval\u001b[1;34m(self, tokens, batch_size, threads)\u001b[0m\n\u001b[0;32m    399\u001b[0m     logger\u001b[39m.\u001b[39mwarning(\n\u001b[0;32m    400\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNumber of tokens (\u001b[39m\u001b[39m{\u001b[39;00mn_past\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39mn_tokens\u001b[39m}\u001b[39;00m\u001b[39m) exceeded maximum context length (\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontext_length\u001b[39m}\u001b[39;00m\u001b[39m).\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    401\u001b[0m     )\n\u001b[0;32m    402\u001b[0m tokens \u001b[39m=\u001b[39m (c_int \u001b[39m*\u001b[39m n_tokens)(\u001b[39m*\u001b[39mtokens)\n\u001b[1;32m--> 403\u001b[0m status \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mctransformers_llm_batch_eval(\n\u001b[0;32m    404\u001b[0m     tokens,\n\u001b[0;32m    405\u001b[0m     n_tokens,\n\u001b[0;32m    406\u001b[0m     n_past,\n\u001b[0;32m    407\u001b[0m     batch_size,\n\u001b[0;32m    408\u001b[0m     threads,\n\u001b[0;32m    409\u001b[0m )\n\u001b[0;32m    410\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m status:\n\u001b[0;32m    411\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mFailed to evaluate tokens.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "out = ''\n",
    "for token in model(get_tokens(dialog), stream=True, top_p=0.9, temperature=0.8, batch_size=1, max_new_tokens=512,):\n",
    "    out += token\n",
    "    print(token, end=\"\", flush=True)\n",
    "dialog.append({\"role\": \"assistant\", \"content\": out})\n",
    "out = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5520d81004d578f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T15:32:46.943102129Z",
     "start_time": "2023-09-28T15:32:31.555425656Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = input().strip()\n",
    "dialog.append({\"role\": \"user\", \"content\": i})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec1c6f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'result': [{'type': 'video', 'id': 'IqwIOlhfCak', 'title': 'LEO - Badass Lyric | Thalapathy Vijay | Lokesh Kanagaraj | Anirudh Ravichander', 'publishedTime': '8 days ago', 'duration': '3:56', 'viewCount': {'text': '21,506,523 views', 'short': '21M views'}, 'thumbnails': [{'url': 'https://i.ytimg.com/vi/IqwIOlhfCak/hq720.jpg?sqp=-oaymwEcCOgCEMoBSFXyq4qpAw4IARUAAIhCGAFwAcABBg==&rs=AOn4CLC4Yag9nJdE1MmM54JLyCkHAuCTCA', 'width': 360, 'height': 202}, {'url': 'https://i.ytimg.com/vi/IqwIOlhfCak/hq720.jpg?sqp=-oaymwEcCNAFEJQDSFXyq4qpAw4IARUAAIhCGAFwAcABBg==&rs=AOn4CLDDuVsH8f_j1yK4PhbrwV8F9tuXWg', 'width': 720, 'height': 404}], 'richThumbnail': {'url': 'https://i.ytimg.com/an_webp/IqwIOlhfCak/mqdefault_6s.webp?du=3000&sqp=CNe8gakG&rs=AOn4CLC1zp0xXLFVF6RveljEcXmDYGL8gA', 'width': 320, 'height': 180}, 'descriptionSnippet': [{'text': 'The Baddest Badass is here! Check out this full-blooded rager featuring the OG Badass #ThalapathyVijay, in the fiery voice of\\xa0...'}], 'channel': {'name': 'Sony Music South', 'id': 'UCn4rEMqKtwBQ6-oEwbd4PcA', 'thumbnails': [{'url': 'https://yt3.ggpht.com/ytc/APkrFKbGREEBS9tvkobo4vxoV9j-no0Hf9tSGx-vx6vp0Q=s68-c-k-c0x00ffffff-no-rj', 'width': 68, 'height': 68}], 'link': 'https://www.youtube.com/channel/UCn4rEMqKtwBQ6-oEwbd4PcA'}, 'accessibility': {'title': 'LEO - Badass Lyric | Thalapathy Vijay | Lokesh Kanagaraj | Anirudh Ravichander by Sony Music South 21,506,523 views 8 days ago 3 minutes, 56 seconds', 'duration': '3 minutes, 56 seconds'}, 'link': 'https://www.youtube.com/watch?v=IqwIOlhfCak', 'shelfTitle': None}]}\n"
     ]
    }
   ],
   "source": [
    "from youtubesearchpython import VideosSearch\n",
    "\n",
    "inp = input()\n",
    "search = VideosSearch(inp,1)\n",
    "id = search.result()['result'][0]['id']\n",
    "#print(search.result()['result'][0]['title'], search.result()['result'][0]['link'], end=\"\\n\")\n",
    "\n",
    "def get_embed_link(youtube_video_id):\n",
    "    return f\"https://www.youtube.com/embed/{youtube_video_id}\"\n",
    "\n",
    "\n",
    "embed_link = get_embed_link(id)\n",
    "\n",
    "print(search.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "410c803b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyttsx3\n",
    "\n",
    "def text_to_audio(text, filename):\n",
    "    engine = pyttsx3.init()\n",
    "    engine.save_to_file(text, filename)\n",
    "    engine.runAndWait()\n",
    "\n",
    "text = 'Everything that you thought had meaning: every hope, dream, or moment of happiness. None of it matters as you lie bleeding out on the battlefield. None of it changes what a speeding rock does to a body, we all die. But does that mean our lives are meaningless? Does that mean that there was no point in our being born? Would you say that of our slain comrades? What about their lives? Were they meaningless?... They were not! Their memory serves as an example to us all! The courageous fallen! The anguished fallen! Their lives have meaning because we the living refuse to forget them! And as we ride to certain death, we trust our successors to do the same for us! Because my soldiers do not buckle or yield when faced with the cruelty of this world! My soldiers push forward! My soldiers scream out! My soldiers RAAAAAGE!\t'\n",
    "\n",
    "import os\n",
    "import string\n",
    "\n",
    "filename = '../flask_server/static/audio/hello_world.mp3'\n",
    "\n",
    "if os.path.exists(filename):\n",
    "    filename = f'../flask_server/static/audio/{os.urandom(16).hex()}.mp3'\n",
    "\n",
    "text_to_audio(text, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "744bc890",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\iamaj\\AppData\\Roaming\\Python\\Python310\\site-packages\\huggingface_hub\\utils\\_hf_folder.py:95: UserWarning: A token has been found in `C:\\Users\\iamaj\\.huggingface\\token`. This is the old path where tokens were stored. The new location is `C:\\Users\\iamaj\\.cache\\huggingface\\token` which is configurable using `HF_HOME` environment variable. Your token has been copied to this new location. You can now safely delete the old token file manually or use `huggingface-cli logout`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41b9cb422d534dc88dd534a06a87a415",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/353 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\iamaj\\AppData\\Roaming\\Python\\Python310\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\iamaj\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a43d89091214493b834b7848c37227ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)embeddings_path.json:   0%|          | 0.00/61.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc5dfd302034413ebfe2fe01a2c90e89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97bafe416f7e4b318982aac5bfa85665",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.92M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71d2607747ca4b4698eee4c8c5840f68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "619aa185575948c18acebdc62c0dcf6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/8.81k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b49afb92a374e26935e39ea290bd994",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/4.49G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Projects\\farm-hub\\notebooks\\testing_dialogue.ipynb Cell 12\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projects/farm-hub/notebooks/testing_dialogue.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m AutoProcessor, BarkModel\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projects/farm-hub/notebooks/testing_dialogue.ipynb#X16sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m processor \u001b[39m=\u001b[39m AutoProcessor\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m\"\u001b[39m\u001b[39msuno/bark\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Projects/farm-hub/notebooks/testing_dialogue.ipynb#X16sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m model \u001b[39m=\u001b[39m BarkModel\u001b[39m.\u001b[39;49mfrom_pretrained(\u001b[39m\"\u001b[39;49m\u001b[39msuno/bark\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projects/farm-hub/notebooks/testing_dialogue.ipynb#X16sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m voice_preset \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mv2/en_speaker_6\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projects/farm-hub/notebooks/testing_dialogue.ipynb#X16sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m inputs \u001b[39m=\u001b[39m processor(\u001b[39m\"\u001b[39m\u001b[39mHello, my dog is cute\u001b[39m\u001b[39m\"\u001b[39m, voice_preset\u001b[39m=\u001b[39mvoice_preset)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\modeling_utils.py:2539\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   2536\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2537\u001b[0m         \u001b[39m# This repo has no safetensors file of any kind, we switch to PyTorch.\u001b[39;00m\n\u001b[0;32m   2538\u001b[0m         filename \u001b[39m=\u001b[39m _add_variant(WEIGHTS_NAME, variant)\n\u001b[1;32m-> 2539\u001b[0m         resolved_archive_file \u001b[39m=\u001b[39m cached_file(\n\u001b[0;32m   2540\u001b[0m             pretrained_model_name_or_path, filename, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcached_file_kwargs\n\u001b[0;32m   2541\u001b[0m         )\n\u001b[0;32m   2542\u001b[0m \u001b[39mif\u001b[39;00m resolved_archive_file \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m filename \u001b[39m==\u001b[39m _add_variant(WEIGHTS_NAME, variant):\n\u001b[0;32m   2543\u001b[0m     \u001b[39m# Maybe the checkpoint is sharded, we try to grab the index name in this case.\u001b[39;00m\n\u001b[0;32m   2544\u001b[0m     resolved_archive_file \u001b[39m=\u001b[39m cached_file(\n\u001b[0;32m   2545\u001b[0m         pretrained_model_name_or_path,\n\u001b[0;32m   2546\u001b[0m         _add_variant(WEIGHTS_INDEX_NAME, variant),\n\u001b[0;32m   2547\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcached_file_kwargs,\n\u001b[0;32m   2548\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\utils\\hub.py:417\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash)\u001b[0m\n\u001b[0;32m    414\u001b[0m user_agent \u001b[39m=\u001b[39m http_user_agent(user_agent)\n\u001b[0;32m    415\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    416\u001b[0m     \u001b[39m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[1;32m--> 417\u001b[0m     resolved_file \u001b[39m=\u001b[39m hf_hub_download(\n\u001b[0;32m    418\u001b[0m         path_or_repo_id,\n\u001b[0;32m    419\u001b[0m         filename,\n\u001b[0;32m    420\u001b[0m         subfolder\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m \u001b[39mif\u001b[39;49;00m \u001b[39mlen\u001b[39;49m(subfolder) \u001b[39m==\u001b[39;49m \u001b[39m0\u001b[39;49m \u001b[39melse\u001b[39;49;00m subfolder,\n\u001b[0;32m    421\u001b[0m         repo_type\u001b[39m=\u001b[39;49mrepo_type,\n\u001b[0;32m    422\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[0;32m    423\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[0;32m    424\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[0;32m    425\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[0;32m    426\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[0;32m    427\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[0;32m    428\u001b[0m         use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[0;32m    429\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[0;32m    430\u001b[0m     )\n\u001b[0;32m    432\u001b[0m \u001b[39mexcept\u001b[39;00m RepositoryNotFoundError:\n\u001b[0;32m    433\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    434\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpath_or_repo_id\u001b[39m}\u001b[39;00m\u001b[39m is not a local folder and is not a valid model identifier \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    435\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlisted on \u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttps://huggingface.co/models\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mIf this is a private repository, make sure to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    436\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpass a token having permission to this repo with `use_auth_token` or log in with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    437\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`huggingface-cli login` and pass `use_auth_token=True`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    438\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\huggingface_hub\\utils\\_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39mif\u001b[39;00m check_use_auth_token:\n\u001b[0;32m    116\u001b[0m     kwargs \u001b[39m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[39m=\u001b[39mfn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, has_token\u001b[39m=\u001b[39mhas_token, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[1;32m--> 118\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\huggingface_hub\\file_download.py:1364\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[1;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout)\u001b[0m\n\u001b[0;32m   1361\u001b[0m \u001b[39mwith\u001b[39;00m temp_file_manager() \u001b[39mas\u001b[39;00m temp_file:\n\u001b[0;32m   1362\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mdownloading \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m to \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, url, temp_file\u001b[39m.\u001b[39mname)\n\u001b[1;32m-> 1364\u001b[0m     http_get(\n\u001b[0;32m   1365\u001b[0m         url_to_download,\n\u001b[0;32m   1366\u001b[0m         temp_file,\n\u001b[0;32m   1367\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[0;32m   1368\u001b[0m         resume_size\u001b[39m=\u001b[39;49mresume_size,\n\u001b[0;32m   1369\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m   1370\u001b[0m         expected_size\u001b[39m=\u001b[39;49mexpected_size,\n\u001b[0;32m   1371\u001b[0m     )\n\u001b[0;32m   1373\u001b[0m \u001b[39mif\u001b[39;00m local_dir \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1374\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mStoring \u001b[39m\u001b[39m{\u001b[39;00murl\u001b[39m}\u001b[39;00m\u001b[39m in cache at \u001b[39m\u001b[39m{\u001b[39;00mblob_path\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\huggingface_hub\\file_download.py:541\u001b[0m, in \u001b[0;36mhttp_get\u001b[1;34m(url, temp_file, proxies, resume_size, headers, timeout, max_retries, expected_size)\u001b[0m\n\u001b[0;32m    531\u001b[0m     displayed_name \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(…)\u001b[39m\u001b[39m{\u001b[39;00mdisplayed_name[\u001b[39m-\u001b[39m\u001b[39m20\u001b[39m:]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    533\u001b[0m progress \u001b[39m=\u001b[39m tqdm(\n\u001b[0;32m    534\u001b[0m     unit\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mB\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    535\u001b[0m     unit_scale\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    539\u001b[0m     disable\u001b[39m=\u001b[39m\u001b[39mbool\u001b[39m(logger\u001b[39m.\u001b[39mgetEffectiveLevel() \u001b[39m==\u001b[39m logging\u001b[39m.\u001b[39mNOTSET),\n\u001b[0;32m    540\u001b[0m )\n\u001b[1;32m--> 541\u001b[0m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m r\u001b[39m.\u001b[39miter_content(chunk_size\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m \u001b[39m*\u001b[39m \u001b[39m1024\u001b[39m \u001b[39m*\u001b[39m \u001b[39m1024\u001b[39m):\n\u001b[0;32m    542\u001b[0m     \u001b[39mif\u001b[39;00m chunk:  \u001b[39m# filter out keep-alive new chunks\u001b[39;00m\n\u001b[0;32m    543\u001b[0m         progress\u001b[39m.\u001b[39mupdate(\u001b[39mlen\u001b[39m(chunk))\n",
      "File \u001b[1;32mc:\\Users\\iamaj\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\requests\\models.py:816\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[1;34m()\u001b[0m\n\u001b[0;32m    814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw, \u001b[39m\"\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    815\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 816\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw\u001b[39m.\u001b[39mstream(chunk_size, decode_content\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    817\u001b[0m     \u001b[39mexcept\u001b[39;00m ProtocolError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    818\u001b[0m         \u001b[39mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[1;32mc:\\Users\\iamaj\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\response.py:628\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m    626\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    627\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m is_fp_closed(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp):\n\u001b[1;32m--> 628\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(amt\u001b[39m=\u001b[39;49mamt, decode_content\u001b[39m=\u001b[39;49mdecode_content)\n\u001b[0;32m    630\u001b[0m         \u001b[39mif\u001b[39;00m data:\n\u001b[0;32m    631\u001b[0m             \u001b[39myield\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\iamaj\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\response.py:567\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[0;32m    564\u001b[0m fp_closed \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp, \u001b[39m\"\u001b[39m\u001b[39mclosed\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    566\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_error_catcher():\n\u001b[1;32m--> 567\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fp_read(amt) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m fp_closed \u001b[39melse\u001b[39;00m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    568\u001b[0m     \u001b[39mif\u001b[39;00m amt \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    569\u001b[0m         flush_decoder \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\iamaj\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\response.py:533\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[39mreturn\u001b[39;00m buffer\u001b[39m.\u001b[39mgetvalue()\n\u001b[0;32m    531\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    532\u001b[0m     \u001b[39m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[1;32m--> 533\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fp\u001b[39m.\u001b[39;49mread(amt) \u001b[39mif\u001b[39;00m amt \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp\u001b[39m.\u001b[39mread()\n",
      "File \u001b[1;32mc:\\Users\\iamaj\\AppData\\Local\\Programs\\Python\\Python310\\lib\\http\\client.py:465\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m amt \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength:\n\u001b[0;32m    463\u001b[0m     \u001b[39m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[0;32m    464\u001b[0m     amt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength\n\u001b[1;32m--> 465\u001b[0m s \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mread(amt)\n\u001b[0;32m    466\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m s \u001b[39mand\u001b[39;00m amt:\n\u001b[0;32m    467\u001b[0m     \u001b[39m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[0;32m    468\u001b[0m     \u001b[39m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[0;32m    469\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_close_conn()\n",
      "File \u001b[1;32mc:\\Users\\iamaj\\AppData\\Local\\Programs\\Python\\Python310\\lib\\socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    703\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m    704\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 705\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[0;32m    706\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[0;32m    707\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\iamaj\\AppData\\Local\\Programs\\Python\\Python310\\lib\\ssl.py:1274\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1270\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1271\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1272\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[0;32m   1273\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[1;32m-> 1274\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[0;32m   1275\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1276\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mc:\\Users\\iamaj\\AppData\\Local\\Programs\\Python\\Python310\\lib\\ssl.py:1130\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1128\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1129\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1130\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[0;32m   1131\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1132\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07d0ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "sample_rate = model.generation_config.sample_rate\n",
    "scipy.io.wavfile.write(\"bark_out.wav\", rate=sample_rate, data=audio_array)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
